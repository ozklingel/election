{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# election prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>area_name</th>\n",
       "      <th>state_abbreviation</th>\n",
       "      <th>AGE135214</th>\n",
       "      <th>AGE295214</th>\n",
       "      <th>AGE775214</th>\n",
       "      <th>SEX255214</th>\n",
       "      <th>RHI225214</th>\n",
       "      <th>RHI325214</th>\n",
       "      <th>RHI425214</th>\n",
       "      <th>...</th>\n",
       "      <th>POP815213</th>\n",
       "      <th>EDU635213</th>\n",
       "      <th>EDU685213</th>\n",
       "      <th>VET605213</th>\n",
       "      <th>LFE305213</th>\n",
       "      <th>state_abbreviation.1</th>\n",
       "      <th>party</th>\n",
       "      <th>candidate</th>\n",
       "      <th>votes</th>\n",
       "      <th>fraction_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>60</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>123</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fips  area_name  state_abbreviation  AGE135214  AGE295214  AGE775214  \\\n",
       "79     29         47                   0         17         12         33   \n",
       "70     20          1                   0          4          0         81   \n",
       "57      7         99                   1         22         28         58   \n",
       "110    60         91                   3         24         27         44   \n",
       "54      4         86                   1         20         32         46   \n",
       "\n",
       "     SEX255214  RHI225214  RHI325214  RHI425214  ...  POP815213  EDU635213  \\\n",
       "79          15          5         41          6  ...         21         78   \n",
       "70           0         21         35         31  ...         76         23   \n",
       "57          50         34          4          2  ...         50          4   \n",
       "110         44         60         42         22  ...         44         76   \n",
       "54          63         82          1          3  ...          1          1   \n",
       "\n",
       "     EDU685213  VET605213  LFE305213  state_abbreviation.1  party  candidate  \\\n",
       "79          72         32         96                     0      0          3   \n",
       "70          15        129         84                     0      0          1   \n",
       "57           9         27         68                     0      0          3   \n",
       "110         79        123         54                     0      0          1   \n",
       "54           3         99         68                     0      0          1   \n",
       "\n",
       "     votes  fraction_votes  \n",
       "79      32              95  \n",
       "70      93              56  \n",
       "57     104              94  \n",
       "110     60              41  \n",
       "54       8              50  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "RANDOMSEED = 40\n",
    "\n",
    "input_data=pd.read_csv(\"C:/Users/97254/Downloads/county_factsNew.csv\",encoding='latin-1')\n",
    "input_data=input_data.iloc[50:180, :].sample(frac=1) # all rows, all the features and no labels\n",
    "\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labelencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder=LabelEncoder()\n",
    "for col in input_data.columns:\n",
    "    input_data[col] = labelencoder.fit_transform(input_data[col].astype(str))\n",
    "\n",
    "target = input_data.iloc[80:150, 22].sample(frac=1)# all ows, label only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# slice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\97254\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From c:\\users\\97254\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\97254\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Step, train accuracy, test accuracy\n",
      "1, 75.86%, 69.77%\n",
      "2, 80.46%, 67.44%\n",
      "3, 79.31%, 65.12%\n",
      "4, 83.91%, 65.12%\n",
      "5, 77.01%, 65.12%\n",
      "6, 80.46%, 65.12%\n",
      "7, 79.31%, 65.12%\n",
      "8, 83.91%, 74.42%\n",
      "9, 82.76%, 69.77%\n",
      "10, 81.61%, 72.09%\n",
      "11, 81.61%, 69.77%\n",
      "12, 83.91%, 65.12%\n",
      "13, 81.61%, 67.44%\n",
      "14, 86.21%, 69.77%\n",
      "15, 82.76%, 65.12%\n",
      "16, 82.76%, 67.44%\n",
      "17, 83.91%, 65.12%\n",
      "18, 80.46%, 65.12%\n",
      "19, 86.21%, 62.79%\n",
      "20, 87.36%, 62.79%\n",
      "21, 88.51%, 60.47%\n",
      "22, 87.36%, 69.77%\n",
      "23, 80.46%, 67.44%\n",
      "24, 87.36%, 58.14%\n",
      "25, 87.36%, 65.12%\n",
      "26, 83.91%, 60.47%\n",
      "27, 82.76%, 65.12%\n",
      "28, 83.91%, 65.12%\n",
      "29, 88.51%, 60.47%\n",
      "30, 90.80%, 65.12%\n",
      "31, 87.36%, 65.12%\n",
      "32, 82.76%, 67.44%\n",
      "33, 85.06%, 69.77%\n",
      "34, 86.21%, 67.44%\n",
      "35, 93.10%, 67.44%\n",
      "36, 89.66%, 62.79%\n",
      "37, 90.80%, 55.81%\n",
      "38, 89.66%, 60.47%\n",
      "39, 88.51%, 58.14%\n",
      "40, 89.66%, 60.47%\n",
      "41, 87.36%, 65.12%\n",
      "42, 86.21%, 62.79%\n",
      "43, 87.36%, 60.47%\n",
      "44, 88.51%, 62.79%\n",
      "45, 90.80%, 62.79%\n",
      "46, 91.95%, 62.79%\n",
      "47, 85.06%, 65.12%\n",
      "48, 91.95%, 60.47%\n",
      "49, 89.66%, 60.47%\n",
      "50, 91.95%, 53.49%\n"
     ]
    }
   ],
   "source": [
    "def load_iris_data():\n",
    "\n",
    "    data=input_data.iloc[:200, 3:21] # all rows, all the features and no labels\n",
    "    target = input_data.iloc[:200, 22]  # all rows, label only\n",
    "\n",
    "    # Prepend the column of 1s for bias\n",
    "    L, W  = data.shape\n",
    "    all_X = np.ones((L, W + 1))\n",
    "    all_X[:, 1:] = data\n",
    "    num_labels = len(np.unique(target))\n",
    "    all_y = np.eye(num_labels)[target]\n",
    "    return train_test_split(all_X, all_y, test_size=0.33, random_state=RANDOMSEED)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_weights(shape, stddev):\n",
    "    weights = tf.random.normal(shape, stddev=stddev)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forward_propagation(X, weights_1, weights_2):\n",
    "    sigmoid = tf.nn.sigmoid(tf.matmul(X, weights_1))\n",
    "    y = tf.matmul(sigmoid, weights_2)\n",
    "    return y\n",
    "\n",
    "def run(h_size, stddev, sgd_step):\n",
    "    train_x, test_x, train_y, test_y = load_iris_data()\n",
    "\n",
    "    # Size of Layers\n",
    "    x_size = train_x.shape[1]  # Input nodes: 23 features and 1 bias\n",
    "    y_size = train_y.shape[1]  # Outcomes (2 types of party)\n",
    "\n",
    "    # variables\n",
    "    X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "    y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "    weights_1 = initialize_weights((x_size, h_size), stddev)\n",
    "    weights_2 = initialize_weights((h_size, y_size), stddev)\n",
    "\n",
    "    #compute forword\n",
    "    y_pred = forward_propagation(X, weights_1, weights_2)\n",
    "    #what get the largest outcome\n",
    "    predict = tf.argmax(y_pred, dimension=1)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_pred))\n",
    "    updates_sgd = tf.train.GradientDescentOptimizer(sgd_step).minimize(cost)\n",
    "    sess = tf.Session()\n",
    "    # init = tf.global_variables_initializer()\n",
    "    init = tf.initialize_all_variables()\n",
    "    steps = 50\n",
    "    sess.run(init)\n",
    "    x  = np.arange(steps)\n",
    "    test_acc = []\n",
    "    train_acc = []\n",
    "    print(\"Step, train accuracy, test accuracy\")\n",
    "    for step in range(steps):\n",
    "        # Train with each example\n",
    "        for i in range(len(train_x)):\n",
    "            sess.run(updates_sgd, feed_dict={X: train_x[i: i + 1], y: train_y[i: i + 1]})\n",
    "\n",
    "        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: train_x, y: train_y}))\n",
    "        test_accuracy = np.mean(np.argmax(test_y, axis=1) ==\n",
    "                                sess.run(predict, feed_dict={X: test_x, y: test_y}))\n",
    "\n",
    "        print(\"%d, %.2f%%, %.2f%%\"\n",
    "              % (step + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "        #x.append(step)\n",
    "        test_acc.append(100. * test_accuracy)\n",
    "        train_acc.append(100. * train_accuracy)\n",
    "\n",
    "    t = [np.array(test_acc)]\n",
    "    t.append(train_acc)\n",
    "    title = \"Steps vs Accuracy-No of hidden nodes: \" + str(h_size) + \", sgd step:\" + str(sgd_step) +             \", std dev:\" + str(stddev)\n",
    "    label = ['Test Accuracy', 'Train Accuracy']\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    run(128,0.1,0.01)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step, train accuracy, test accuracy\n",
      "1, 70.11%, 55.81%\n",
      "2, 71.26%, 53.49%\n",
      "3, 73.56%, 60.47%\n",
      "4, 77.01%, 62.79%\n",
      "5, 75.86%, 62.79%\n",
      "6, 77.01%, 65.12%\n",
      "7, 81.61%, 65.12%\n",
      "8, 83.91%, 65.12%\n",
      "9, 82.76%, 65.12%\n",
      "10, 86.21%, 65.12%\n",
      "11, 88.51%, 65.12%\n",
      "12, 90.80%, 67.44%\n",
      "13, 91.95%, 67.44%\n",
      "14, 91.95%, 69.77%\n",
      "15, 91.95%, 67.44%\n",
      "16, 93.10%, 67.44%\n",
      "17, 93.10%, 67.44%\n",
      "18, 93.10%, 67.44%\n",
      "19, 93.10%, 67.44%\n",
      "20, 93.10%, 67.44%\n",
      "21, 94.25%, 67.44%\n",
      "22, 94.25%, 67.44%\n",
      "23, 94.25%, 67.44%\n",
      "24, 95.40%, 67.44%\n",
      "25, 96.55%, 65.12%\n",
      "26, 96.55%, 65.12%\n",
      "27, 97.70%, 67.44%\n",
      "28, 97.70%, 67.44%\n",
      "29, 97.70%, 67.44%\n",
      "30, 97.70%, 67.44%\n",
      "31, 97.70%, 67.44%\n",
      "32, 97.70%, 67.44%\n",
      "33, 97.70%, 67.44%\n",
      "34, 97.70%, 67.44%\n",
      "35, 97.70%, 69.77%\n",
      "36, 97.70%, 69.77%\n",
      "37, 97.70%, 69.77%\n",
      "38, 97.70%, 69.77%\n",
      "39, 97.70%, 69.77%\n",
      "40, 97.70%, 69.77%\n",
      "41, 97.70%, 69.77%\n",
      "42, 97.70%, 69.77%\n",
      "43, 97.70%, 69.77%\n",
      "44, 97.70%, 69.77%\n",
      "45, 97.70%, 69.77%\n",
      "46, 97.70%, 69.77%\n",
      "47, 97.70%, 69.77%\n",
      "48, 97.70%, 69.77%\n",
      "49, 97.70%, 69.77%\n",
      "50, 97.70%, 69.77%\n"
     ]
    }
   ],
   "source": [
    "def load_iris_data():\n",
    "\n",
    "    data=input_data.iloc[:200, 3:21] # all rows, all the features and no labels\n",
    "    target = input_data.iloc[:200, 22]  # all rows, label only\n",
    "\n",
    "    # Prepend the column of 1s for bias\n",
    "    L, W  = data.shape\n",
    "    all_X = np.ones((L, W + 1))\n",
    "    all_X[:, 1:] = data\n",
    "    num_labels = len(np.unique(target))\n",
    "    all_y = np.eye(num_labels)[target]\n",
    "    return train_test_split(all_X, all_y, test_size=0.33, random_state=RANDOMSEED)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_weights(shape, stddev):\n",
    "    weights = tf.random.normal(shape, stddev=stddev)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forward_propagation(X, weights_1, weights_2):\n",
    "    sigmoid = tf.nn.sigmoid(tf.matmul(X, weights_1))\n",
    "    y = tf.matmul(sigmoid, weights_2)\n",
    "    return y\n",
    "\n",
    "def run(h_size, stddev, sgd_step):\n",
    "    train_x, test_x, train_y, test_y = load_iris_data()\n",
    "\n",
    "    # Size of Layers\n",
    "    x_size = train_x.shape[1]  # Input nodes: 23 features and 1 bias\n",
    "    y_size = train_y.shape[1]  # Outcomes (2 types of party)\n",
    "\n",
    "    # variables\n",
    "    X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "    y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "    weights_1 = initialize_weights((x_size, h_size), stddev)\n",
    "    weights_2 = initialize_weights((h_size, y_size), stddev)\n",
    "\n",
    "    #compute forword\n",
    "    y_pred = forward_propagation(X, weights_1, weights_2)\n",
    "    #what get the largest outcome\n",
    "    predict = tf.argmax(y_pred, dimension=1)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_pred))\n",
    "    updates_sgd = tf.train.GradientDescentOptimizer(sgd_step).minimize(cost)\n",
    "    sess = tf.Session()\n",
    "    # init = tf.global_variables_initializer()\n",
    "    init = tf.initialize_all_variables()\n",
    "    steps = 50\n",
    "    sess.run(init)\n",
    "    x  = np.arange(steps)\n",
    "    test_acc = []\n",
    "    train_acc = []\n",
    "    print(\"Step, train accuracy, test accuracy\")\n",
    "    for step in range(steps):\n",
    "        # Train with each example\n",
    "        for i in range(len(train_x)):\n",
    "            sess.run(updates_sgd, feed_dict={X: train_x[i: i + 1], y: train_y[i: i + 1]})\n",
    "\n",
    "        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: train_x, y: train_y}))\n",
    "        test_accuracy = np.mean(np.argmax(test_y, axis=1) ==\n",
    "                                sess.run(predict, feed_dict={X: test_x, y: test_y}))\n",
    "\n",
    "        print(\"%d, %.2f%%, %.2f%%\"\n",
    "              % (step + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "        #x.append(step)\n",
    "        test_acc.append(100. * test_accuracy)\n",
    "        train_acc.append(100. * train_accuracy)\n",
    "\n",
    "    t = [np.array(test_acc)]\n",
    "    t.append(train_acc)\n",
    "    title = \"Steps vs Accuracy-No of hidden nodes: \" + str(h_size) + \", sgd step:\" + str(sgd_step) +             \", std dev:\" + str(stddev)\n",
    "    label = ['Test Accuracy', 'Train Accuracy']\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    run(128,0.1,0.001)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step, train accuracy, test accuracy\n",
      "1, 58.62%, 44.19%\n",
      "2, 70.11%, 51.16%\n",
      "3, 72.41%, 53.49%\n",
      "4, 80.46%, 60.47%\n",
      "5, 80.46%, 62.79%\n",
      "6, 83.91%, 62.79%\n",
      "7, 85.06%, 62.79%\n",
      "8, 87.36%, 65.12%\n",
      "9, 87.36%, 67.44%\n",
      "10, 88.51%, 65.12%\n",
      "11, 88.51%, 65.12%\n",
      "12, 89.66%, 65.12%\n",
      "13, 89.66%, 69.77%\n",
      "14, 88.51%, 67.44%\n",
      "15, 88.51%, 65.12%\n",
      "16, 88.51%, 62.79%\n",
      "17, 90.80%, 62.79%\n",
      "18, 90.80%, 65.12%\n",
      "19, 90.80%, 65.12%\n",
      "20, 90.80%, 65.12%\n",
      "21, 90.80%, 65.12%\n",
      "22, 94.25%, 65.12%\n",
      "23, 94.25%, 65.12%\n",
      "24, 94.25%, 65.12%\n",
      "25, 94.25%, 65.12%\n",
      "26, 95.40%, 65.12%\n",
      "27, 96.55%, 65.12%\n",
      "28, 96.55%, 65.12%\n",
      "29, 96.55%, 65.12%\n",
      "30, 96.55%, 65.12%\n",
      "31, 96.55%, 65.12%\n",
      "32, 96.55%, 65.12%\n",
      "33, 97.70%, 65.12%\n",
      "34, 97.70%, 65.12%\n",
      "35, 97.70%, 65.12%\n",
      "36, 97.70%, 65.12%\n",
      "37, 97.70%, 62.79%\n",
      "38, 97.70%, 62.79%\n",
      "39, 97.70%, 62.79%\n",
      "40, 97.70%, 62.79%\n",
      "41, 97.70%, 62.79%\n",
      "42, 97.70%, 60.47%\n",
      "43, 97.70%, 60.47%\n",
      "44, 97.70%, 60.47%\n",
      "45, 98.85%, 60.47%\n",
      "46, 98.85%, 60.47%\n",
      "47, 98.85%, 60.47%\n",
      "48, 98.85%, 60.47%\n",
      "49, 98.85%, 60.47%\n",
      "50, 98.85%, 60.47%\n"
     ]
    }
   ],
   "source": [
    "def load_iris_data():\n",
    "\n",
    "    data=input_data.iloc[:200, 3:21] # all rows, all the features and no labels\n",
    "    target = input_data.iloc[:200, 22]  # all rows, label only\n",
    "\n",
    "    # Prepend the column of 1s for bias\n",
    "    L, W  = data.shape\n",
    "    all_X = np.ones((L, W + 1))\n",
    "    all_X[:, 1:] = data\n",
    "    num_labels = len(np.unique(target))\n",
    "    all_y = np.eye(num_labels)[target]\n",
    "    return train_test_split(all_X, all_y, test_size=0.33, random_state=RANDOMSEED)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initialize_weights(shape, stddev):\n",
    "    weights = tf.random.normal(shape, stddev=stddev)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def forward_propagation(X, weights_1, weights_2):\n",
    "    sigmoid = tf.nn.sigmoid(tf.matmul(X, weights_1))\n",
    "    y = tf.matmul(sigmoid, weights_2)\n",
    "    return y\n",
    "\n",
    "def run(h_size, stddev, sgd_step):\n",
    "    train_x, test_x, train_y, test_y = load_iris_data()\n",
    "\n",
    "    # Size of Layers\n",
    "    x_size = train_x.shape[1]  # Input nodes: 23 features and 1 bias\n",
    "    y_size = train_y.shape[1]  # Outcomes (2 types of party)\n",
    "\n",
    "    # variables\n",
    "    X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "    y = tf.placeholder(\"float\", shape=[None, y_size])\n",
    "    weights_1 = initialize_weights((x_size, h_size), stddev)\n",
    "    weights_2 = initialize_weights((h_size, y_size), stddev)\n",
    "\n",
    "    #compute forword\n",
    "    y_pred = forward_propagation(X, weights_1, weights_2)\n",
    "    #what get the largest outcome\n",
    "    predict = tf.argmax(y_pred, dimension=1)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_pred))\n",
    "    updates_sgd = tf.train.GradientDescentOptimizer(sgd_step).minimize(cost)\n",
    "    sess = tf.Session()\n",
    "    # init = tf.global_variables_initializer()\n",
    "    init = tf.initialize_all_variables()\n",
    "    steps = 50\n",
    "    sess.run(init)\n",
    "    x  = np.arange(steps)\n",
    "    test_acc = []\n",
    "    train_acc = []\n",
    "    print(\"Step, train accuracy, test accuracy\")\n",
    "    for step in range(steps):\n",
    "        # Train with each example\n",
    "        for i in range(len(train_x)):\n",
    "            sess.run(updates_sgd, feed_dict={X: train_x[i: i + 1], y: train_y[i: i + 1]})\n",
    "\n",
    "        train_accuracy = np.mean(np.argmax(train_y, axis=1) ==\n",
    "                                 sess.run(predict, feed_dict={X: train_x, y: train_y}))\n",
    "        test_accuracy = np.mean(np.argmax(test_y, axis=1) ==\n",
    "                                sess.run(predict, feed_dict={X: test_x, y: test_y}))\n",
    "\n",
    "        print(\"%d, %.2f%%, %.2f%%\"\n",
    "              % (step + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "        #x.append(step)\n",
    "        test_acc.append(100. * test_accuracy)\n",
    "        train_acc.append(100. * train_accuracy)\n",
    "\n",
    "    t = [np.array(test_acc)]\n",
    "    t.append(train_acc)\n",
    "    title = \"Steps vs Accuracy-No of hidden nodes: \" + str(h_size) + \", sgd step:\" + str(sgd_step) +             \", std dev:\" + str(stddev)\n",
    "    label = ['Test Accuracy', 'Train Accuracy']\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    run(140,0.1,0.001)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
